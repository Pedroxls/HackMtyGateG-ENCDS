# routes/predict.py
from fastapi import APIRouter, Query
from openai import OpenAI
import os, json, random, re

router = APIRouter()

client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY")
)

def parse_duration(duration_str: str) -> str:
    try:
        hours, minutes = map(int, duration_str.split(":"))
        parts = []
        if hours > 0:
            parts.append(f"{hours} hora{'s' if hours != 1 else ''}")
        if minutes > 0:
            parts.append(f"{minutes} minutos")
        return " y ".join(parts)
    except Exception:
        return "duraci√≥n desconocida"

def format_report_text(report: str) -> str:
    # Limpiar escapes de salto de l√≠nea
    report_clean = report.replace('\\n\\n', '\n\n').replace('\\n', '\n').strip()

    # Eliminar negritas innecesarias
    report_clean = report_clean.replace("**", "")

    # Quitar puntos intermedios tipo lista Markdown
    report_clean = report_clean.replace("* ", "")

    # Quitar doble espacio al inicio de l√≠neas
    report_clean = "\n".join([line.lstrip() for line in report_clean.splitlines()])

    # Insertar saltos dobles entre secciones tipo "1. Producto"
    report_clean = re.sub(r"(?<=\n)(\d+\.\s+\w+.*?)\n", r"\n\1\n", report_clean)

    # Asegurar separaci√≥n entre p√°rrafos
    lines = report_clean.splitlines()
    formatted = ""
    for i, line in enumerate(lines):
        formatted += line + "\n"
        if i + 1 < len(lines) and lines[i + 1].strip() == "":
            formatted += "\n"
    return formatted.strip()


def try_parse_json_with_fix(raw: str) -> dict:
    try:
        return json.loads(raw)
    except json.JSONDecodeError:
        print("‚ö†Ô∏è JSON inv√°lido. Intentando reparar...")
        # A√±adir llaves faltantes
        if raw.count('{') > raw.count('}'):
            raw += "}" * (raw.count('{') - raw.count('}'))

        # Cerrar comillas de 'report' si est√°n abiertas
        match = re.search(r'"report":\s*"(.*)', raw)
        if match and not raw.strip().endswith('"'):
            raw = re.sub(r'"report":\s*"(.*)', r'"report": "\1..." }', raw)

        return json.loads(raw)

@router.get("/predict")
async def get_predictions(
    origin_country: str = Query(...),
    flight_duration: str = Query(...),
    time_of_day: str = Query(...),
    confirmed_passengers: int = Query(...),
):
    products = ["Galletas Oreo", "Agua Mineral 500ml", "Sandwich Club"]
    readable_duration = parse_duration(flight_duration)

    prompt = (
        f"Eres un experto en an√°lisis de consumo a bordo de vuelos internacionales. "
        f"Recibiste los siguientes par√°metros:\n"
        f"- Pa√≠s de origen del vuelo: {origin_country}\n"
        f"- Duraci√≥n estimada: {readable_duration}\n"
        f"- Hora del despegue: {time_of_day}\n"
        f"- Pasajeros confirmados: {confirmed_passengers}\n\n"
        f"Analiza el contexto y elabora un informe ejecutivo claro y profesional que incluya:\n"
        f"1. Predicciones para estos productos: {', '.join(products)}, con su demanda esperada (n√∫mero) y tendencia ('up', 'down', 'steady').\n"
        f"2. Justificaci√≥n detallada para cada producto, basada en duraci√≥n, origen, n√∫mero de pasajeros, preferencias culturales y horario del vuelo.\n"
        f"3. Usa referencias o supuestos reales si es posible (como costumbres, h√°bitos o datos relevantes del pa√≠s de origen).\n\n"
        f"Devuelve un JSON con:\n"
        f"- 'predictions': lista de objetos con 'product', 'predicted_demand' y 'trend'\n"
        f"- 'report': p√°rrafo extenso profesional y sin comillas ni formato de string literal (estilo texto libre, no encerrado en comillas)."
    )

    try:
        response = client.chat.completions.create(
            model="google/gemini-2.5-flash",
            messages=[
                {"role": "system", "content": "Eres un analista profesional redactando reportes para ejecutivos de aerol√≠neas."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=850,
            temperature=0.4
        )

        raw = response.choices[0].message.content.strip()
        print("üì• Respuesta cruda de OpenAI:\n", raw)

        if raw.startswith("```json"):
            raw = raw.replace("```json", "").replace("```", "").strip()
        elif raw.startswith("```"):
            raw = raw.replace("```", "").strip()

        json_data = try_parse_json_with_fix(raw)
        predictions = json_data["predictions"]
        report = format_report_text(json_data["report"])

    except Exception as e:
        print("‚ùå Error en la predicci√≥n:", e)
        predictions = [
            {
                "product": p,
                "predicted_demand": random.randint(85, 150),
                "trend": random.choice(["up", "down", "steady"])
            }
            for p in products
        ]
        report = (
            "Este reporte es gen√©rico debido a un error inesperado.\n\n"
            "Predicciones simuladas por respaldo, basadas en patrones hist√≥ricos aleatorios."
        )

    return {"predictions": predictions, "report": report}

@router.get("/trend-explanation")
async def explain_trend(
    country: str = Query(...),
    trend: str = Query(...)
):
    print(f"üõ∞Ô∏è Recibida petici√≥n para pa√≠s: {country}, tendencia: {trend}")

    trend = trend.strip().lower().replace('"', '').replace("'", '')

    if trend not in ["up", "down", "steady"]:
        return {"country": country, "trend": trend, "explanation": "Tendencia inv√°lida."}

    prompt = (
        f"Eres un analista experto en comportamiento de consumo a bordo de vuelos internacionales.\n"
        f"Explica en m√°ximo 4 l√≠neas por qu√© un pa√≠s como {country} podr√≠a tener una tendencia de consumo '{trend}'.\n"
        f"Considera factores culturales, h√°bitos de viaje, horarios o clima si aplica."
    )

    try:
        print("üì§ Enviando prompt a Gemini...")
        response = client.chat.completions.create(
            model="google/gemini-2.5-flash",
            messages=[
                {"role": "system", "content": "Responde como experto en an√°lisis de consumo de aerol√≠neas. S√© profesional, breve y claro."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=300,
            temperature=0.5
        )
        explanation = response.choices[0].message.content.strip()
        print("üì• Explicaci√≥n generada:", explanation)
        return {"country": country, "trend": trend, "explanation": explanation}

    except Exception as e:
        print("‚ùå Error al generar explicaci√≥n de tendencia:", e)
        return {
            "country": country,
            "trend": trend,
            "explanation": "No se pudo generar una explicaci√≥n en este momento."
        }
